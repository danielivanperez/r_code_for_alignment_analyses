---
title: "R Notebook for Simulating Baselines with a Leave-one-out Approach"
output:
  html_document:
    df_print: paged
---

In this notebook, I describe the steps I took to simulate distributions through a boostrapping approach using Juliet's R code. 

In the code below, we can set the number of options (or unique responses for open ended questions), sample size and number of iterations.  

```{r}
rm(list = ls()) #this just resets any variables you already have saved in the R session so you're starting with a fresh worksheet

n_options = 4 # With this bit we can set the number of picks i.e. 4 
n_sample = 25 # Here we can set the number of participants 
n = 10000 #number of times you want it to iterate. 
```


In the chunk below, we build the customized function "CI_t", whose outputs will be six: sample size, mean, standard deviation, margin error,CI lower limit, and CI Upper limit. We can use this function when we have calculated the full set of simulated alignment values (see below). 

```{r}
#function for calculating CI
#value for ci is the size of the interval required e.g. 0.95 is a 95% interval
CI_t <- function (x, ci = 0.95){
  `%>%` <- magrittr::`%>%`
  #qt() gets the t-distribution
  Margin_Error <- qt(ci + (1 - ci)/2, df = length(x) - 1) * sd(x)/sqrt(length(x))
  df_out <- data.frame( sample_size=length(x), Mean=mean(x), sd=sd(x),
                        Margin_Error=Margin_Error,
                        'CI lower limit'=(mean(x) - Margin_Error),
                        'CI Upper limit'=(mean(x) + Margin_Error)) %>%
    tidyr::pivot_longer(names_to = "Measurements", values_to ="values", 1:6 )
  return(df_out)
}
```

Now in the following chunk, we are going to build the customised function "chance_sim". This function allows us to simulate responses at random.

```{r}
# simulate data to just get the 'chance level' (not alignment score) --------------------
chance_sim<-function(n_options,n_sample){
  
  #creates a big empty data set as wide as the number of options and as long as the sample size
  sim_data <- data.frame(matrix(0, ncol = n_options, nrow = n_sample))

  #assigns a 1 to each 'participant' (each row)
  #by picking a column (an option) at random 
  for(i in 1:n_sample){
    pick<-as.numeric(sample(c(1:n_options),1,replace=T))
    sim_data[i,pick]<-1
  }                                
  
  #gets the mean of each option 
  #multiples that by the number of times it was picked
  #add them all together and divides by number of participants 
  #to get the actual mean of the proportions - this is the baseline
  proportions=0
  for (i in 1:ncol(sim_data)){
    pick_mean<-mean(sim_data[,i])
    pick_sum<-sum(sim_data[,i])
    proportions<-proportions+(pick_mean*pick_sum)
  }
  
  baseline<-proportions/n_sample
  
  #returns a single figure for the 'chance level' for that dataset
  return(baseline)
  
}

```


```{r}
#sim_data <- 
data.frame(matrix(0, ncol = n_options, nrow = n_sample))
```


I run the "chance_sim" function two times below to know the mean we get with 4 options for a sample size of 25 participants. 

```{r}
chance_sim(4,25) #gets a single simulated baseline as an example (not alignment score)
```

```{r}
chance_sim(4,25) #gets a single simulated baseline as an example (not alignment score)
```

In the next step, we can apply the CI_t function built above to the 10,000 values simulated using the bootstrapping approach, whose values are stored in the variable "boot_chance"


```{r}
#simulates a baseline with a new dataset n times and takes the mean of all n baselines
boot_chance <- replicate(1000, {mean_chance<-chance_sim(n_options,n_sample)})
boot_mean <- mean(boot_chance)


CI_t(boot_chance,ci=0.95)
```


```{r}
library(gmodels)
variable_ci <- ci(boot_chance)
variable_ci
```


In the output above, we are getting a mean of 0.2799 from the 10,000 iterations (a value more similar to what was suggested by one of the reviewers I think) with the corresponding 95% Confident intervals. 

But now we're going to apply the leave one out method to the bootstrapping simulated values. For this, we build the "chance_alignment_sim" function. 

```{r}
# #using the leave one out method to get a random/chance sample of alignment scores --------

chance_alignment_sim<-function(n_options,n_sample){
  
  #creates a big empty data set as wide as the number of options and as long as the sample size
  sim_data <- data.frame(matrix(0, ncol = n_options, nrow = n_sample))
  
  #assigns a 1 to each 'participant' (each row)
  #by picking a column (an option) at random 
  for(i in 1:n_sample){
    pick<-as.numeric(sample(c(1:n_options),1,replace=T))
    sim_data[i,pick]<-1
  }                                
  
  # Gets the alignment score for each simulated participant
  # method: for each row, looks in each column
  # for the column with a 1 in it: column sum -1 / sample size -1
  alignments<-list()
  for (i in 1:nrow(sim_data)){
    for (j in 1:ncol(sim_data)){
      if (sim_data[i,j]==1){
        pt_alignment<-(sum(sim_data[,j])-1)/(n_sample-1)
      }
    }
    alignments[[i]]<-pt_alignment
  }
  
  #returns a list of n_sample alignment scores
  return(alignments)
  
}
```

Applying this function, we can get the alignment scores from the number of options (eg 4) for the number of participants of our study (eg, 25).

```{r}
chance_alignment_sim(4,10) #gets a list of simulated alignment scores as an example
```
Now we will replicate this process 10,000 times with the "replicate function", and we store the complete array of values in the "boot_alignment" variable. Then, we apply the mean function to this variable. Next, we apply the CI_t function to the "boot_alignment" variable (ie, full array of 10,000 values). 

```{r}
boot_alignment <- replicate(10000,{mean_alignment<-mean(unlist(chance_alignment_sim(n_options,n_sample)))})

boot_mean_alignment <- mean(boot_alignment)

CI_alignment<-CI_t(boot_alignment,ci=0.95)
CI_alignment

```

Below we return the values stored in "CI_alignment" variable. 

```{r}
CI_alignment
```

Now we plot the 10,000 values stored in boot_alignment. 

```{r}
hist(boot_alignment)
```
Juliet also added this chunk to plot the values to get a normal distribution just in case we want to check it. 

```{r}
# to resample from the simulated data in order to get a normal distribution --------
# this appears to be unnecessary but keeping it in for reference 
library(boot) 

# function to obtain the mean from a sample of the data
Bmean <- function(data, indices) {
  d <- data[indices] # allows boot to select sample 
  return(mean(d))
} 

# bootstrapping with 10000 replications 
# this is a built in function in R
#This is using the chance sim not the alignment sim but could be done with either
#Would just need to change data=boot_chance to data=boot_alignment
boot_sample_means <- boot(data=boot_alignment, statistic=Bmean, R=10000)
```

```{r}
boot_sample_means 
plot(boot_sample_means) # view results
```

In the chunk below, I've calculated the 95%CI for 5 options and 30 participants with 10,000 iterations for reference purposes only. 

```{r}
boot_alignment_2 <- replicate(10000,{mean_alignment<-mean(unlist(chance_alignment_sim(5,30)))})

boot_mean_alignment_2 <- mean(boot_alignment_2)

CI_alignment_2<-CI_t(boot_alignment_2,ci=0.95)
CI_alignment_2

```
Now we plot the 10,000 values stored in boot_alignment_2. 

```{r}
hist(boot_alignment_2)
```
 I've finally calculated the 95%CI for 10 options and 30 participants with 10,000 iterations for reference purposes only. 

```{r}
boot_alignment_3 <- replicate(10000,{mean_alignment<-mean(unlist(chance_alignment_sim(10,30)))})

boot_mean_alignment_3 <- mean(boot_alignment_3)

CI_alignment_3<-CI_t(boot_alignment_3,ci=0.95)
CI_alignment_3

```
Now we plot the 10,000 values stored in boot_alignment_3. 

```{r}
hist(boot_alignment_3)
```

```{r}
boot_alignment_4 <- replicate(10000,{mean_alignment<-mean(unlist(chance_alignment_sim(22,25)))})

boot_mean_alignment_4 <- mean(boot_alignment_4)

CI_alignment_4<-CI_t(boot_alignment_4,ci=0.95)
CI_alignment_4

```
```{r}
1/22
```

```{r}
dieroll_data <- c(sample(1:6, 10, replace=TRUE))
```

```{r}
print(dieroll_data)
```

```{r}
Bob_card<-c(1:13)
Bobs_friend_card_1<-c(1:13)
Bobs_friend_card_2<-c(1:13)
Bobs_friend_card_3<-c(1:13)
```

```{r}
sample(Bob_card,1)
sample(Bobs_friend_card_1,1)
```
```{r}
bob_results <- replicate(100,sample(Bob_card,1, replace = TRUE))
bobs_friend_results_1 <- replicate(100,sample(Bobs_friend_card_1,1,replace = TRUE))
bobs_friend_results_2 <- replicate(100,sample(Bobs_friend_card_2,1,replace = TRUE))
bobs_friend_results_3 <- replicate(100,sample(Bobs_friend_card_3,1,replace = TRUE))
```

```{r}
proportion <- (table(bob_results > bobs_friend_results))/100
print(proportion)
```

```{r}
condition_data <- data.frame(BOB = bob_results,BOB_FRIEND_1 = bobs_friend_results_1, BOB_FRIEND_2 = bobs_friend_results_2, BOB_FRIEND_3 = bobs_friend_results_3)
```


```{r}
#condition_data$column <- 

condition_data$logical_value <-ifelse(condition_data$BOB > c(condition_data$BOB_FRIEND_1 & condition_data$BOB_FRIEND_2 & condition_data$BOB_FRIEND_3),"greater","lesser")
```



